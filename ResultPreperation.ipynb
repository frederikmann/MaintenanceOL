{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "from parts import collect, cleaning, oie, domain_relevance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collecting\n",
    "either from stored txt files or topic link in motor forum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load post files\n",
    "def load_files(limit):\n",
    "    counter = 0\n",
    "    path = \"resources/txt/car/\"\n",
    "    corpus = []\n",
    "    while counter < limit:\n",
    "        try:\n",
    "            with open(path + \"/\" + str(counter) + \".txt\", \"r\", encoding = \"utf-8\") as file:\n",
    "                corpus.append(file.read())\n",
    "            counter += 1\n",
    "        except FileNotFoundError:\n",
    "            counter += 1\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = load_files(1500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OIE\n",
    "extract terms and root words from each sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1190/1190 [40:44<00:00,  2.05s/it]\n"
     ]
    }
   ],
   "source": [
    "# precleaning -> delete questions, short sentences\n",
    "corpus_no_questions = []\n",
    "for doc in tqdm(corpus):\n",
    "    clean_doc = cleaning.sentences(doc, 1)\n",
    "    corpus_no_questions.append(clean_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1190/1190 [04:26<00:00,  4.47it/s]\n"
     ]
    }
   ],
   "source": [
    "roots, terms = [],[]\n",
    "\n",
    "for post in tqdm(corpus_no_questions):\n",
    "    post_roots, post_terms, _ = oie.get_oie(post)\n",
    "    roots.extend(post_roots)\n",
    "    terms.extend(post_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "backup_roots = roots\n",
    "backup_terms = terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleted time references: 0\n",
      "deleted date references: 250\n",
      "deleted links: 764\n",
      "deleted quotes: 0\n",
      "deleted ireg expressions: 0\n",
      "deleted abbreviations: 1347\n"
     ]
    }
   ],
   "source": [
    "# post cleaning of terms\n",
    "clean_terms = cleaning.terms(terms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Domain Relevancy\n",
    "narrow down terms to domain relevant terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load concept list from domain relevancy file\n",
    "with open(\"audi_concepts.txt\", \"r\") as f:\n",
    "    content = f.readlines()\n",
    "concepts = [x.strip() for x in content] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load list of german stopwords \n",
    "with open(\"resources/stopwords_ger.txt\", \"r\") as f:\n",
    "    content = f.readlines()\n",
    "stop_words = [x.strip() for x in content] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get concepts from list and ignoring stopwords\n",
    "domain_concepts = []  \n",
    "for sent in clean_terms:\n",
    "    t = set()\n",
    "    for term in sent:\n",
    "        if term in concepts and term not in stop_words:\n",
    "            t.add(term)\n",
    "    domain_concepts.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>roots</th>\n",
       "      <th>terms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lg</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hab</td>\n",
       "      <td>teile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rückleuchtenband</td>\n",
       "      <td>heckklappengriff, avant, c4, rückleuchtenband</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>können</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>können</td>\n",
       "      <td>rückleuchtenband</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              roots                                          terms\n",
       "0                lg                                               \n",
       "1               hab                                          teile\n",
       "2  rückleuchtenband  heckklappengriff, avant, c4, rückleuchtenband\n",
       "3            können                                               \n",
       "4            können                               rückleuchtenband"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataframe visualisation\n",
    "terms2 = []\n",
    "for sent in domain_concepts:\n",
    "    terms2.append(\", \".join(sent))\n",
    "\n",
    "df = pd.DataFrame(roots, columns=[\"roots\"])\n",
    "df[\"terms\"] = pd.DataFrame(terms2)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete empty sets\n",
    "roots_2 = []\n",
    "terms_2 = []\n",
    "for root, sent in zip(roots, domain_concepts):\n",
    "    if sent:\n",
    "        roots_2.append(root)\n",
    "        terms_2.append(sent)\n",
    "roots = roots_2\n",
    "terms = terms_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Association Rule Mining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search all relations for most common words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_term_relations(terms, roots, window_size=1):\n",
    "    cooccurrence = dict()\n",
    "    indicies = set()\n",
    "    \n",
    "    for root, sent in zip(roots, terms):\n",
    "        for term_x in sent:\n",
    "            for term_y in sent:\n",
    "                index = term_x + \",\" + term_y\n",
    "                reverse_index = term_y + \",\" + term_x\n",
    "                if term_x == term_y:\n",
    "                    pass\n",
    "                elif reverse_index in indicies:\n",
    "                    pass\n",
    "                elif index not in indicies and reverse_index not in indicies:\n",
    "                    indicies.add(index)\n",
    "                    cooccurrence[index] = [root]\n",
    "                else:\n",
    "                    cooccurrence[index].append(root)\n",
    "    return cooccurrence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cooccurrence = get_term_relations(terms, roots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get most common relation#\n",
    "from collections import Counter\n",
    "\n",
    "relations = {}\n",
    "\n",
    "for index in cooccurrence:\n",
    "    relations[index] = Counter(cooccurrence[index]).most_common(1)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_terms = [item for sublist in domain_concepts for item in sublist]\n",
    "df = pd.Series(Counter(flat_terms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(ascending= False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common_terms = Counter(flat_terms).most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_term_x = []\n",
    "common_term_y = []\n",
    "common_relation = []\n",
    "\n",
    "for a in most_common_terms:\n",
    "    for b in most_common_terms:\n",
    "        index = a[0] + \",\" + b[0]\n",
    "        reverse_index = b[0] + \",\" + a[0]\n",
    "        if index in relations:\n",
    "            common_term_x.append(a[0])\n",
    "            common_term_y.append(b[0])\n",
    "            common_relation.append(relations[index])\n",
    "        elif reverse_index in relations:\n",
    "            common_term_x.append(a[0])\n",
    "            common_term_y.append(b[0])\n",
    "            common_relation.append(relations[reverse_index])\n",
    "        else: \n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search most common relation for seed words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_word = \"vergleich\"\n",
    "window_size = 2\n",
    "\n",
    "window_terms = []\n",
    "window_roots = []\n",
    "seed_relations = []\n",
    "\n",
    "for root, sent in zip(roots, terms):\n",
    "    window_terms.append(sent)\n",
    "    window_roots.append(root)\n",
    "    flat_terms = [item for sublist in window_terms for item in sublist]\n",
    "    if seed_word in flat_terms:\n",
    "        for window_root, window_sent in zip(window_roots, window_terms):\n",
    "            for window_term in window_sent:\n",
    "                if window_term == seed_word or window_term == window_root:\n",
    "                    pass\n",
    "                else:\n",
    "                    relation = window_root + \",\" + window_term\n",
    "                    seed_relations.append(relation)\n",
    "    if len(window_roots) > window_size:\n",
    "        window_terms.pop(0)\n",
    "        window_roots.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(seed_relations).most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_seed_relation(terms, roots, seed_word, window_size = 1, limit = 3):\n",
    "    window_terms = []\n",
    "    window_roots = []\n",
    "    seed_relations = []\n",
    "\n",
    "    for root, sent in zip(roots, terms):\n",
    "        window_terms.append(sent)\n",
    "        window_roots.append(root)\n",
    "        flat_terms = [item for sublist in window_terms for item in sublist]\n",
    "        if seed_word in flat_terms:\n",
    "            for window_root, window_sent in zip(window_roots, window_terms):\n",
    "                for window_term in window_sent:\n",
    "                    if window_term == seed_word or window_term == window_root:\n",
    "                        pass\n",
    "                    else:\n",
    "                        relation = window_root + \",\" + window_term\n",
    "                        seed_relations.append(relation)\n",
    "        if len(window_roots) > window_size:\n",
    "            window_terms.pop(0)\n",
    "            window_roots.pop(0)\n",
    "    \n",
    "    return Counter(seed_relations).most_common(limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_terms = [item for sublist in domain_concepts for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common_terms = Counter(flat_terms).most_common(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_term_x = []\n",
    "seed_term_y = []\n",
    "seed_relation = []\n",
    "\n",
    "for term in most_common_terms:\n",
    "    seed_relations = get_seed_relation(terms, roots, term[0], 3, 5)\n",
    "    for relation in seed_relations:\n",
    "        if relation[1] > 3:\n",
    "            relation_root, relation_term_y = relation[0].split(\",\")\n",
    "            if relation_root != \"schreiben\":\n",
    "                seed_term_x.append(term[0])\n",
    "                seed_term_y.append(relation_term_y)\n",
    "                seed_relation.append(relation_root)\n",
    "        else:\n",
    "            print(\"min relation number not reached\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add GermaNet Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load GermaNet data...: 100%|██████████████████████████████████████████▉| 99.99999999999996/100 [00:24<00:00,  4.13it/s]\n",
      "Load Wictionary data...: 100%|████████████████████████████████████████████████████| 100.0/100 [00:00<00:00, 413.24it/s]\n",
      "Load Ili records...: 100%|███████████████████████████████████████████████████████| 100.0/100 [00:00<00:00, 9966.74it/s]\n"
     ]
    }
   ],
   "source": [
    "from germanetpy.germanet import Germanet\n",
    "\n",
    "path = \"D:/Users/STUD_Mann.AIS/GermaNet\" \n",
    "\n",
    "data_path = path + \"/GN_V150/GN_V150_XML\"\n",
    "frequencylist_nouns = path + \"/GN_V150/FreqLists/noun_freqs_decow14_16.txt\"\n",
    "germanet = Germanet(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset(id=s8813, lexunits=Automobil, Auto, Kraftfahrzeug, Wagen, Kraftwagen, Motorwagen, Motorfahrzeug, Kfz)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "germanet.get_synsets_by_orthform(\"Auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_germanetinfo(termlist):\n",
    "    germanetinfo = []\n",
    "    for term in termlist:\n",
    "        terminfo = []\n",
    "        orthform = term[0].swapcase() + term[1:]\n",
    "        if germanet.get_synsets_by_orthform(orthform):\n",
    "            for synset in germanet.get_synsets_by_orthform(orthform):\n",
    "                #find shortest hierachial path to root (Entität)\n",
    "                root_path = synset.shortest_path(germanet.get_synset_by_id(\"s51001\"))\n",
    "                terminfo.append(root_path)\n",
    "            germanetinfo.append(terminfo)\n",
    "        else:\n",
    "            germanetinfo.append(None)\n",
    "            \n",
    "    return germanetinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_term_x_germanetinfo = get_germanetinfo(seed_term_x)\n",
    "seed_term_y_germanetinfo = get_germanetinfo(seed_term_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303\n",
      "443\n"
     ]
    }
   ],
   "source": [
    "print(sum(x is not None for x in seed_term_x_germanetinfo))\n",
    "print(len(seed_term_x_germanetinfo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found  645 out of  886 terms\n"
     ]
    }
   ],
   "source": [
    "sum_x = sum(x is not None for x in seed_term_x_germanetinfo)\n",
    "len_x = len(seed_term_x_germanetinfo)\n",
    "sum_y = sum(x is not None for x in seed_term_y_germanetinfo)\n",
    "len_y = len(seed_term_y_germanetinfo)\n",
    "\n",
    "print(\"found \", sum_x+sum_y, \"out of \", len_x+len_y, \"terms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx \n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "\n",
    "G = nx.Graph()\n",
    "nodeA = seed_term_x\n",
    "nodeB = seed_term_y\n",
    "relation = seed_relation\n",
    "\n",
    "for a, b in zip(nodeA, nodeB):\n",
    "    G.add_edge(a, b)\n",
    "\n",
    "pos = nx.spring_layout(G, k=0.15, iterations=20)\n",
    "plt.figure(figsize=(12,12))\n",
    "nx.draw(G,pos,width=1,linewidths=1,node_size=500,alpha=0.9,labels={node:node for node in G.nodes()})\n",
    "labels = dict(zip(list(zip(nodeA, nodeB)),relation))\n",
    "nx.draw_networkx_edge_labels(G,pos,edge_labels=labels,font_color='red')\n",
    "\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(seed_term_x, columns=[\"Node A\"])\n",
    "df[\"Node B\"] = pd.DataFrame(seed_term_y)\n",
    "df[\"Root\"] = pd.DataFrame(seed_relation)\n",
    "df[\"GermaNet A\"] = pd.Series(seed_term_x_germanetinfo)\n",
    "df[\"GermaNet B\"] = pd.Series(seed_term_y_germanetinfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Node A</th>\n",
       "      <th>Node B</th>\n",
       "      <th>Root</th>\n",
       "      <th>GermaNet A</th>\n",
       "      <th>GermaNet B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>audi</td>\n",
       "      <td>b4</td>\n",
       "      <td>habe</td>\n",
       "      <td>[[[Synset(id=s27145, lexunits=Audi), Synset(id...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>audi</td>\n",
       "      <td>b4</td>\n",
       "      <td>fahren</td>\n",
       "      <td>[[[Synset(id=s27145, lexunits=Audi), Synset(id...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>audi</td>\n",
       "      <td>km</td>\n",
       "      <td>haben</td>\n",
       "      <td>[[[Synset(id=s27145, lexunits=Audi), Synset(id...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>audi</td>\n",
       "      <td>km</td>\n",
       "      <td>fahren</td>\n",
       "      <td>[[[Synset(id=s27145, lexunits=Audi), Synset(id...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>audi</td>\n",
       "      <td>motor</td>\n",
       "      <td>haben</td>\n",
       "      <td>[[[Synset(id=s27145, lexunits=Audi), Synset(id...</td>\n",
       "      <td>[[[Synset(id=s139757, lexunits=Motor), Synset(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>motor</td>\n",
       "      <td>audi</td>\n",
       "      <td>habe</td>\n",
       "      <td>[[[Synset(id=s139757, lexunits=Motor), Synset(...</td>\n",
       "      <td>[[[Synset(id=s27145, lexunits=Audi), Synset(id...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>motor</td>\n",
       "      <td>audi</td>\n",
       "      <td>haben</td>\n",
       "      <td>[[[Synset(id=s139757, lexunits=Motor), Synset(...</td>\n",
       "      <td>[[[Synset(id=s27145, lexunits=Audi), Synset(id...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>motor</td>\n",
       "      <td>audi</td>\n",
       "      <td>fahren</td>\n",
       "      <td>[[[Synset(id=s139757, lexunits=Motor), Synset(...</td>\n",
       "      <td>[[[Synset(id=s27145, lexunits=Audi), Synset(id...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>motor</td>\n",
       "      <td>gas</td>\n",
       "      <td>geben</td>\n",
       "      <td>[[[Synset(id=s139757, lexunits=Motor), Synset(...</td>\n",
       "      <td>[[[Synset(id=s8920, lexunits=Gaspedal, Gas), S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>motor</td>\n",
       "      <td>probleme</td>\n",
       "      <td>haben</td>\n",
       "      <td>[[[Synset(id=s139757, lexunits=Motor), Synset(...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>auto</td>\n",
       "      <td>audi</td>\n",
       "      <td>fahren</td>\n",
       "      <td>[[[Synset(id=s8813, lexunits=Automobil, Auto, ...</td>\n",
       "      <td>[[[Synset(id=s27145, lexunits=Audi), Synset(id...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>auto</td>\n",
       "      <td>audi</td>\n",
       "      <td>habe</td>\n",
       "      <td>[[[Synset(id=s8813, lexunits=Automobil, Auto, ...</td>\n",
       "      <td>[[[Synset(id=s27145, lexunits=Audi), Synset(id...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>auto</td>\n",
       "      <td>audi</td>\n",
       "      <td>haben</td>\n",
       "      <td>[[[Synset(id=s8813, lexunits=Automobil, Auto, ...</td>\n",
       "      <td>[[[Synset(id=s27145, lexunits=Audi), Synset(id...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>auto</td>\n",
       "      <td>motor</td>\n",
       "      <td>gehen</td>\n",
       "      <td>[[[Synset(id=s8813, lexunits=Automobil, Auto, ...</td>\n",
       "      <td>[[[Synset(id=s139757, lexunits=Motor), Synset(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>auto</td>\n",
       "      <td>audi</td>\n",
       "      <td>können</td>\n",
       "      <td>[[[Synset(id=s8813, lexunits=Automobil, Auto, ...</td>\n",
       "      <td>[[[Synset(id=s27145, lexunits=Audi), Synset(id...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>km</td>\n",
       "      <td>audi</td>\n",
       "      <td>fahren</td>\n",
       "      <td>None</td>\n",
       "      <td>[[[Synset(id=s27145, lexunits=Audi), Synset(id...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>km</td>\n",
       "      <td>motor</td>\n",
       "      <td>laufen</td>\n",
       "      <td>None</td>\n",
       "      <td>[[[Synset(id=s139757, lexunits=Motor), Synset(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>km</td>\n",
       "      <td>audi</td>\n",
       "      <td>haben</td>\n",
       "      <td>None</td>\n",
       "      <td>[[[Synset(id=s27145, lexunits=Audi), Synset(id...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>km</td>\n",
       "      <td>motor</td>\n",
       "      <td>haben</td>\n",
       "      <td>None</td>\n",
       "      <td>[[[Synset(id=s139757, lexunits=Motor), Synset(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>km</td>\n",
       "      <td>audi</td>\n",
       "      <td>habe</td>\n",
       "      <td>None</td>\n",
       "      <td>[[[Synset(id=s27145, lexunits=Audi), Synset(id...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Node A    Node B    Root  \\\n",
       "0    audi        b4    habe   \n",
       "1    audi        b4  fahren   \n",
       "2    audi        km   haben   \n",
       "3    audi        km  fahren   \n",
       "4    audi     motor   haben   \n",
       "5   motor      audi    habe   \n",
       "6   motor      audi   haben   \n",
       "7   motor      audi  fahren   \n",
       "8   motor       gas   geben   \n",
       "9   motor  probleme   haben   \n",
       "10   auto      audi  fahren   \n",
       "11   auto      audi    habe   \n",
       "12   auto      audi   haben   \n",
       "13   auto     motor   gehen   \n",
       "14   auto      audi  können   \n",
       "15     km      audi  fahren   \n",
       "16     km     motor  laufen   \n",
       "17     km      audi   haben   \n",
       "18     km     motor   haben   \n",
       "19     km      audi    habe   \n",
       "\n",
       "                                           GermaNet A  \\\n",
       "0   [[[Synset(id=s27145, lexunits=Audi), Synset(id...   \n",
       "1   [[[Synset(id=s27145, lexunits=Audi), Synset(id...   \n",
       "2   [[[Synset(id=s27145, lexunits=Audi), Synset(id...   \n",
       "3   [[[Synset(id=s27145, lexunits=Audi), Synset(id...   \n",
       "4   [[[Synset(id=s27145, lexunits=Audi), Synset(id...   \n",
       "5   [[[Synset(id=s139757, lexunits=Motor), Synset(...   \n",
       "6   [[[Synset(id=s139757, lexunits=Motor), Synset(...   \n",
       "7   [[[Synset(id=s139757, lexunits=Motor), Synset(...   \n",
       "8   [[[Synset(id=s139757, lexunits=Motor), Synset(...   \n",
       "9   [[[Synset(id=s139757, lexunits=Motor), Synset(...   \n",
       "10  [[[Synset(id=s8813, lexunits=Automobil, Auto, ...   \n",
       "11  [[[Synset(id=s8813, lexunits=Automobil, Auto, ...   \n",
       "12  [[[Synset(id=s8813, lexunits=Automobil, Auto, ...   \n",
       "13  [[[Synset(id=s8813, lexunits=Automobil, Auto, ...   \n",
       "14  [[[Synset(id=s8813, lexunits=Automobil, Auto, ...   \n",
       "15                                               None   \n",
       "16                                               None   \n",
       "17                                               None   \n",
       "18                                               None   \n",
       "19                                               None   \n",
       "\n",
       "                                           GermaNet B  \n",
       "0                                                None  \n",
       "1                                                None  \n",
       "2                                                None  \n",
       "3                                                None  \n",
       "4   [[[Synset(id=s139757, lexunits=Motor), Synset(...  \n",
       "5   [[[Synset(id=s27145, lexunits=Audi), Synset(id...  \n",
       "6   [[[Synset(id=s27145, lexunits=Audi), Synset(id...  \n",
       "7   [[[Synset(id=s27145, lexunits=Audi), Synset(id...  \n",
       "8   [[[Synset(id=s8920, lexunits=Gaspedal, Gas), S...  \n",
       "9                                                None  \n",
       "10  [[[Synset(id=s27145, lexunits=Audi), Synset(id...  \n",
       "11  [[[Synset(id=s27145, lexunits=Audi), Synset(id...  \n",
       "12  [[[Synset(id=s27145, lexunits=Audi), Synset(id...  \n",
       "13  [[[Synset(id=s139757, lexunits=Motor), Synset(...  \n",
       "14  [[[Synset(id=s27145, lexunits=Audi), Synset(id...  \n",
       "15  [[[Synset(id=s27145, lexunits=Audi), Synset(id...  \n",
       "16  [[[Synset(id=s139757, lexunits=Motor), Synset(...  \n",
       "17  [[[Synset(id=s27145, lexunits=Audi), Synset(id...  \n",
       "18  [[[Synset(id=s139757, lexunits=Motor), Synset(...  \n",
       "19  [[[Synset(id=s27145, lexunits=Audi), Synset(id...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"audi_auswertung_top100-w3-l5.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

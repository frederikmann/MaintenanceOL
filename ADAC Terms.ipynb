{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Term Extraction: ADAC Rückrufe\n",
    "https://www.adac.de/infotestrat/reparatur-pflege-und-wartung/rueckrufe/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import requests as req\n",
    "from bs4 import BeautifulSoup\n",
    "from parts import collect, preprocessing, oie, domain_relevance\n",
    "\n",
    "nlp = spacy.load(\"de_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# provide link with make given and open option for model\n",
    "# i.e. \"https://www.adac.de/infotestrat/reparatur-pflege-und-wartung/rueckrufe/suchergebnis.aspx?Kategorie=Pkw&Hersteller=Audi&Modelle=\"\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "def get_adac_links():\n",
    "    link = \"https://www.adac.de/infotestrat/reparatur-pflege-und-wartung/rueckrufe/suchergebnis.aspx?Kategorie=Pkw\"\n",
    "    make_list = []\n",
    "    links = []\n",
    "    \n",
    "    r = req.get(link)\n",
    "    soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "    makes = soup.find(\"select\", {\"class\":\"w190\"})\n",
    "    for option in makes.find_all(\"option\"):\n",
    "            make_list.append(option.text)\n",
    "    \n",
    "    make_list.remove(\"Alle Hersteller\")\n",
    "    make_list.remove(\"\")\n",
    "    \n",
    "    for make in tqdm(make_list):\n",
    "        make_link = link+\"&Hersteller=\"+make\n",
    "        r = req.get(make_link)\n",
    "        soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "        models = soup.find(\"select\", {\"class\":\"w190 left\"})\n",
    "        if models:\n",
    "            for option in models.find_all(\"option\"):\n",
    "                links.append(make_link+\"&Modelle=\"+option.text)\n",
    "        \n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:21<00:00,  3.34it/s]\n"
     ]
    }
   ],
   "source": [
    "links = get_adac_links()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_adac(link):\n",
    "    meldung = set()\n",
    "    \n",
    "    r = req.get(link)\n",
    "    soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "    \n",
    "    for p in soup.find_all(\"p\", {\"class\": \"pl13\"}):\n",
    "        meldung.add(p.text)\n",
    "        \n",
    "    return meldung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def get_adac_domain(links):\n",
    "    meldungen = []\n",
    "    \n",
    "    for link in tqdm(links):\n",
    "        meldungen.extend(get_text_adac(link))\n",
    "    \n",
    "    return set(meldungen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2670/2670 [11:58<00:00,  3.71it/s]\n"
     ]
    }
   ],
   "source": [
    "adac_domain = get_adac_domain(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2719"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(adac_domain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_terms(corpus):\n",
    "    terms = []\n",
    "    \n",
    "    doc = nlp(corpus.lower())\n",
    "    \n",
    "    for token in doc:\n",
    "        if token.pos_ in [\"NOUN\", \"PROPN\"] and not token.is_stop:\n",
    "            terms.append(token.lemma_)\n",
    "    \n",
    "    return terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = [get_terms(doc) for doc in adac_domain]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def get_tf(terms):\n",
    "    flat_terms = [item for sublist in terms for item in sublist]\n",
    "    tf = Counter(flat_terms)\n",
    "    max_freq = Counter(flat_terms).most_common(1)[0][1]\n",
    "    for t in tf:\n",
    "        tf[t] = (tf[t]/max_freq)\n",
    "    \n",
    "    return tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_idf(terms):\n",
    "    flat_terms = [item for sublist in terms for item in set(sublist)]\n",
    "    idf = Counter(flat_terms)\n",
    "    for t in idf:\n",
    "        idf[t] = np.log2(len(terms)/idf[t])\n",
    "    \n",
    "    return idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_tdf(terms):\n",
    "    flat_terms = [item for sublist in terms for item in set(sublist)]\n",
    "    tdf = Counter(flat_terms)\n",
    "    for t in tdf:\n",
    "        tdf[t] = tdf[t]/len(terms)\n",
    "    \n",
    "    return tdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = get_tf(terms)\n",
    "idf = get_idf(terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = {}\n",
    "\n",
    "for term in set([item for sublist in terms for item in sublist]):\n",
    "    tf_idf[term] = tf[term]*idf[term]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.Series(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "aktion                        1.000000\n",
       "kunden                        0.936317\n",
       "stunden                       0.561962\n",
       "händler                       0.511188\n",
       "fahrzeugen                    0.343373\n",
       "abhilfe                       0.272806\n",
       "hersteller                    0.259897\n",
       "fahrzeuge                     0.222031\n",
       "werkstatt                     0.220310\n",
       "code                          0.216007\n",
       "hersteller-werkstattsystem    0.192771\n",
       "folgen                        0.157487\n",
       "fahrzeug                      0.148021\n",
       "fall                          0.142857\n",
       "ausfall                       0.126506\n",
       "eintrag                       0.104991\n",
       "maßnahme                      0.097246\n",
       "austausch                     0.092083\n",
       "bereich                       0.086919\n",
       "unfall                        0.086919\n",
       "dtype: float64"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(ascending = False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index().to_csv(\"adac_terms.csv\", index = False, header=True, sep = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_term_cleaning(terms):\n",
    "    # clean zitate, datum, zeichen/ zahlen only terms, zeit, links\n",
    "    clean_terms = []\n",
    "    time, date, link, zitat, ireg, abbr = 0, 0, 0, 0, 0, 0\n",
    "    abbreviations = preprocessing.get_abbr()\n",
    "\n",
    "    for doc in terms:\n",
    "        clean_doc = []\n",
    "        for term in doc:\n",
    "            if len(term) < 2:\n",
    "                pass\n",
    "            elif re.search(r\"\\d\\d:\\d\\d:\\d\\d\", term):\n",
    "                time += 1\n",
    "            elif re.search(r\"\\d\\d.\\d\\d.\\d\\d\\d\\d\", term):\n",
    "                date += 1\n",
    "            elif re.search(\"https://\", term):\n",
    "                link += 1\n",
    "            elif re.search(\"@\", term):\n",
    "                zitat += 1\n",
    "            elif term in abbreviations:\n",
    "                abbr += 1\n",
    "            elif re.search(r\"\\w\", term):\n",
    "                clean_doc.append(term)\n",
    "            elif re.search(r\"^\\W\", term):\n",
    "                ireg += 1\n",
    "            else:\n",
    "                print(term)\n",
    "        clean_terms.append(clean_doc)\n",
    "\n",
    "    print(\"deleted time references:\", time)\n",
    "    print(\"deleted date references:\", date)\n",
    "    print(\"deleted links:\", link)\n",
    "    print(\"deleted quotes:\", zitat)\n",
    "    print(\"deleted ireg expressions:\", ireg)\n",
    "    print(\"deleted abbreviations:\", abbr)\n",
    "\n",
    "    return clean_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleted time references: 0\n",
      "deleted date references: 118\n",
      "deleted links: 1\n",
      "deleted quotes: 8\n",
      "deleted ireg expressions: 2\n",
      "deleted abbreviations: 35\n"
     ]
    }
   ],
   "source": [
    "clean_terms = post_term_cleaning(terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = get_tf(clean_terms)\n",
    "idf = get_idf(clean_terms)\n",
    "tdf = get_tdf(clean_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = {}\n",
    "tf_tdf = {}\n",
    "\n",
    "for term in set([item for sublist in clean_terms for item in sublist]):\n",
    "    tf_idf[term] = tf[term]*idf[term]\n",
    "    tf_tdf[term] = tf[term]*tdf[term]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.Series(tf_tdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index().to_csv(\"adac_terms.csv\", index = False, header=True, sep = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spacy",
   "language": "python",
   "name": "spacy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Domain Relevance Evaluation\n",
    "\n",
    "Comparing different methods to get domain relevant terms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from parts import collect, oie, domain_relevance, cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Load of Background Domains\n",
    "\n",
    "!!! only needed first time -> choose to export data to resource folder for faster performance in the future !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "adac_corpus = collect.get_corpus(0,\"adac\",0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chefkoch_corpus = collect.get_corpus(\"https://www.chefkoch.de/forum/1,27/Haus-Garten.html\",\"chefkoch\",5,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_corpus = collect.get_corpus(\"https://www.motor-talk.de/forum/audi-80-90-100-200-v8-b158.html\",\"car\",3,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Background Domains and Extract Terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2524/2524 [01:22<00:00, 30.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleted time references: 0\n",
      "deleted date references: 287\n",
      "deleted links: 77\n",
      "deleted quotes: 63\n",
      "deleted ireg expressions: 38\n",
      "deleted abbreviations: 206\n"
     ]
    }
   ],
   "source": [
    "adac_domain = collect.load_domain_terms(\"adac\", 10000, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 174/174 [00:17<00:00,  9.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleted time references: 19\n",
      "deleted date references: 29\n",
      "deleted links: 89\n",
      "deleted quotes: 367\n",
      "deleted ireg expressions: 122\n",
      "deleted abbreviations: 241\n"
     ]
    }
   ],
   "source": [
    "car_domain = collect.load_domain_terms(\"car\", 10000, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 279/279 [01:21<00:00,  3.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleted time references: 0\n",
      "deleted date references: 692\n",
      "deleted links: 156\n",
      "deleted quotes: 419\n",
      "deleted ireg expressions: 321\n",
      "deleted abbreviations: 491\n"
     ]
    }
   ],
   "source": [
    "chefkoch_domain = collect.load_domain_terms(\"chefkoch\", 10000, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = \"tf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adac_relevance = domain_relevance.get_relevancy(adac_domain, metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_relevance = domain_relevance.get_relevancy(car_domain, metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chefkoch_relevance = domain_relevance.get_relevancy(chefkoch_domain, metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.5\n",
    "candidates = set([item for sublist in car_domain for item in sublist])\n",
    "dw = domain_relevance.get_dw(car_domain, chefkoch_domain, candidates, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llr = domain_relevance.get_llr(car_domain, chefkoch_domain, candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lor_bg = domain_relevance.get_lor_bg(car_domain, chefkoch_domain, candidates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of Metrics and Domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Term frequency distribution in car_domain\n",
    "from collections import Counter\n",
    "flat_terms = [item for sublist in chefkoch_domain for item in sublist]\n",
    "tf = Counter(flat_terms)\n",
    "bins= range(0,15,1)\n",
    "plt.hist(tf.values(), bins=bins, edgecolor=\"k\")\n",
    "plt.xticks(bins)\n",
    "print(min(tf.values()),max(tf.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# distribution of llr, dw, lor, lor_bg values (just exchange for fitting metric)\n",
    "bins= range(int(min(llr.values()))-1,int(min(llr.values()))+10,1)\n",
    "plt.hist(llr.values(), bins=bins, edgecolor=\"k\")\n",
    "plt.xticks(bins)\n",
    "print(min(llr.values()),max(llr.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# overview of highest and lowest performing terms in metric\n",
    "pd.Series(tf).sort_values(ascending = False).head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(candidates)\n",
    "counter = 0\n",
    "chefkoch_terms = set([item for sublist in chefkoch_domain for item in sublist])\n",
    "for term in candidates:\n",
    "    if term in chefkoch_terms and tf[term] > 1:\n",
    "        counter += 1\n",
    "        \n",
    "counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Concept Export and Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concepts = list(set([item for sublist in adac_domain for item in sublist]))\n",
    "with open(\"concepts.txt\", \"w\") as fp:\n",
    "    fp.writelines('\\n'.join(concepts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"concepts.txt\", \"r\") as f:\n",
    "    content = f.readlines()\n",
    "# you may also want to remove whitespace characters like `\\n` at the end of each line\n",
    "content = [x.strip() for x in content] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Random Testset and Test Concept generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from random import sample\n",
    "#\n",
    "#testset = sample(candidates, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"testset.txt\", \"r\") as f:\n",
    "    testset = f.readlines()\n",
    "# you may also want to remove whitespace characters like `\\n` at the end of each line\n",
    "testset = [x.strip() for x in testset] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "reader = csv.reader(open('testset_labeled.csv', 'r'),delimiter=';')\n",
    "labeled = {}\n",
    "for row in reader:\n",
    "    k,v = row\n",
    "    labeled[k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 174/174 [00:00<00:00, 39089.92it/s]\n",
      "100%|██████████| 279/279 [00:00<00:00, 21276.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen via background domain: 974\n",
      "Chosen via metric: 187\n",
      "Chosen via tf > 1 limit: 1927\n"
     ]
    }
   ],
   "source": [
    "labels = domain_relevance.label_concepts(car_domain, adac_domain, chefkoch_domain, \"llr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = {}\n",
    "for candidate in testset:\n",
    "    predicted[candidate] = labels[candidate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame.from_dict(labeled,orient='index', columns = [\"label\"])\n",
    "df[\"predicted\"] = predicted.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 53, 112],\n",
       "       [ 22, 313]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(pd.to_numeric(df[\"label\"]), pd.to_numeric(df[\"predicted\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.32      0.44       165\n",
      "           1       0.74      0.93      0.82       335\n",
      "\n",
      "    accuracy                           0.73       500\n",
      "   macro avg       0.72      0.63      0.63       500\n",
      "weighted avg       0.73      0.73      0.70       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(pd.to_numeric(df[\"label\"]), pd.to_numeric(df[\"predicted\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CRCTL domain relevance measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 174/174 [00:00<00:00, 43219.76it/s]\n",
      "100%|██████████| 279/279 [00:00<00:00, 23230.45it/s]\n"
     ]
    }
   ],
   "source": [
    "shared_target_domain, shared_contrastive_domain = domain_relevance.get_shared_domain(car_domain, chefkoch_domain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates = set([item for sublist in car_domain for item in sublist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "### macht einfach keinen sinn der bumms\n",
    "\n",
    "def get_lambda(target_domain, contrastive_domain, candidates):\n",
    "    lambda_metric = {}\n",
    "    \n",
    "    target_tf = domain_relevance.get_tf(target_domain, 1)\n",
    "    contrast_tf = domain_relevance.get_tf(contrastive_domain, 1)\n",
    "    \n",
    "    target_len = len([item for sublist in target_domain for item in sublist])\n",
    "    contrast_len = len([item for sublist in contrastive_domain for item in sublist])\n",
    "    \n",
    "    for term in candidates:\n",
    "        a = target_tf[term]\n",
    "        b = contrast_tf[term]\n",
    "        \n",
    "        n1 = target_len\n",
    "        n2 = contrast_len\n",
    "        \n",
    "        p = (a+b) / (n1 + n2)\n",
    "        p1 = a / n1\n",
    "        p2 = a / n2\n",
    "        \n",
    "        lambda_metric[term] = ( p ** a * (1-p) ** (n1-a) * p ** b * (1-p) ** (n2-b) ) / ( p1 ** a * (1-p1) ** (n1-a) * p2 ** b * (1-p2) ** (n2-b) )\n",
    "    \n",
    "    return lambda_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spacy",
   "language": "python",
   "name": "spacy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

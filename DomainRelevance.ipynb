{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Domain Relevance Evaluation\n",
    "\n",
    "Getting domain relevant terms via presented domain relevancy decision tree - methods are listed in parts/domain_relevancy.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from parts import collect, oie, domain_relevance, cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Load of Background Domains\n",
    "\n",
    "!!! only needed first time -> choose to export data to resource folder for faster performance in the future !!!\n",
    "\n",
    "collect.get_corpus set-up for three different scenarios: adac, chefkoch, car - each detailing different methods for scraping the text from the website. In each case the function takes a root link page and starts scraping links from this one and the following one until the limit is reached. Then each link is scraped and stored in a folder if needed. \n",
    "\n",
    "parameters: collect.get_corpus(root_link, domain type, limit link pages, export to folder?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#adac_corpus = collect.get_corpus(0,\"adac\",0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chefkoch_corpus = collect.get_corpus(\"https://www.chefkoch.de/forum/1,27/Haus-Garten.html\",\"chefkoch\",50,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#car_corpus = collect.get_corpus(\"https://www.motor-talk.de/forum/audi-80-90-100-200-v8-b158.html\",\"car\",30,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Background Domains and Extract Terms\n",
    "\n",
    "simply loading the scraped forum pages from the respecitve folders.\n",
    "\n",
    "parameters: collect.load_domain_terms(domain, limit pages, clean?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2530/2530 [01:21<00:00, 31.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleted time references: 0\n",
      "deleted date references: 287\n",
      "deleted links: 77\n",
      "deleted quotes: 63\n",
      "deleted ireg expressions: 41\n",
      "deleted abbreviations: 203\n"
     ]
    }
   ],
   "source": [
    "adac_domain = collect.load_domain_terms(\"adac\", 10000, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1216/1216 [05:12<00:00,  3.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleted time references: 220\n",
      "deleted date references: 198\n",
      "deleted links: 689\n",
      "deleted quotes: 3263\n",
      "deleted ireg expressions: 2412\n",
      "deleted abbreviations: 1721\n"
     ]
    }
   ],
   "source": [
    "car_domain = collect.load_domain_terms(\"car_bmw\", 10000, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1190/1190 [06:15<00:00,  3.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleted time references: 229\n",
      "deleted date references: 339\n",
      "deleted links: 952\n",
      "deleted quotes: 3420\n",
      "deleted ireg expressions: 2955\n",
      "deleted abbreviations: 1772\n"
     ]
    }
   ],
   "source": [
    "audi_domain = collect.load_domain_terms(\"car\", 10000, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2548/2548 [10:32<00:00,  4.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleted time references: 0\n",
      "deleted date references: 1455\n",
      "deleted links: 1008\n",
      "deleted quotes: 1648\n",
      "deleted ireg expressions: 1985\n",
      "deleted abbreviations: 2232\n"
     ]
    }
   ],
   "source": [
    "chefkoch_domain = collect.load_domain_terms(\"chefkoch\", 10000, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of Metrics and Domains\n",
    "\n",
    "!!! Not needed for domain relevancy evaluation !!!\n",
    "\n",
    "This section provides and overview of frequency distributions within the scraped domains - adobt the functions to see details about other domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distribution of metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracted terms 403041 , extracted concepts 99667\n"
     ]
    }
   ],
   "source": [
    "flat_terms = [item for sublist in car_domain for item in sublist]\n",
    "tf = Counter(flat_terms)\n",
    "print(\"extracted terms\", len(flat_terms), \", extracted concepts\", len(tf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Term frequency distribution in car_domain\n",
    "from collections import Counter\n",
    "flat_terms = [item for sublist in car_domain for item in sublist]\n",
    "tf = Counter(flat_terms)\n",
    "bins= range(0,15,1)\n",
    "plt.hist(tf.values(), bins=bins, edgecolor=\"k\")\n",
    "plt.xticks(bins)\n",
    "print(min(tf.values()),max(tf.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# distribution of llr, dw, lor, lor_bg values (just exchange for fitting metric)\n",
    "bins= range(int(min(llr.values()))-1,int(min(llr.values()))+10,1)\n",
    "plt.hist(llr.values(), bins=bins, edgecolor=\"k\")\n",
    "plt.xticks(bins)\n",
    "print(min(llr.values()),max(llr.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bmw            7114\n",
       "km             4372\n",
       "auto           4362\n",
       "motor          3974\n",
       "problem        2458\n",
       "wagen          2227\n",
       "hallo          2035\n",
       "werkstatt      1813\n",
       "fehler         1738\n",
       "1er            1665\n",
       "probleme       1629\n",
       "steuerkette    1490\n",
       "fragen         1459\n",
       "öl             1296\n",
       "fahrzeug       1282\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# overview of highest and lowest performing terms in metric\n",
    "pd.Series(tf).sort_values(ascending = False).head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(candidates)\n",
    "counter = 0\n",
    "chefkoch_terms = set([item for sublist in chefkoch_domain for item in sublist])\n",
    "for term in candidates:\n",
    "    if term in chefkoch_terms and tf[term] > 1:\n",
    "        counter += 1\n",
    "        \n",
    "counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concept Export and Import\n",
    "\n",
    "In this section concepts are labeled and exported. This is done with the domain_relevance.label_concepts() function. By default it returns the results of the metric and method chosen in the thesis! Optionally the different metrics and methods can be used to label concepts. \n",
    "\n",
    "methods: \"dw\", \"llr\", \"lor-bg\", \"del\"\n",
    "\n",
    "metrics: \"tf\", \"idf\", \"tdf\", \"tf-tdf\", \"tf-idf\"\n",
    "\n",
    "parameters: domain_relevance.label_concepts(target domain, background domain, contrastive domain, method, metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 1216/1216 [00:00<00:00, 5544.96it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 2548/2548 [00:00<00:00, 9685.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen via background domain: 2272\n",
      "Chosen via metric: 3664\n",
      "Chosen via tf > 1 limit: 15133\n"
     ]
    }
   ],
   "source": [
    "labels = domain_relevance.label_concepts(car_domain, adac_domain, chefkoch_domain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concepts = set()\n",
    "\n",
    "for term in labels:\n",
    "    if labels[term]:\n",
    "        concepts.add(term)\n",
    "\n",
    "concepts = list(concepts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concepts = list(set([item for sublist in adac_domain for item in sublist]))\n",
    "with open(\"bmw_concepts.txt\", \"w\") as fp:\n",
    "    fp.writelines('\\n'.join(concepts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### only needed to re-import the concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"concepts.txt\", \"r\") as f:\n",
    "    content = f.readlines()\n",
    "# you may also want to remove whitespace characters like `\\n` at the end of each line\n",
    "content = [x.strip() for x in content] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testset comparison\n",
    "\n",
    "Two test sets were created to evaluate the different domain relevancy methods and metrics. Load the testset and the labeled testset and perform the required domain relevancy method - evalution is provided by sklearn library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testset_w-uniques.txt\n",
    "# testset.txt\n",
    "\n",
    "with open(\"testset_w-uniques.txt\", \"r\", encoding =\"utf-8\") as f:\n",
    "    testset = f.readlines()\n",
    "# you may also want to remove whitespace characters like `\\n` at the end of each line\n",
    "testset = [x.strip() for x in testset] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testset_w-unique_labeled.csv\n",
    "# testset_labeled.csv\n",
    "\n",
    "import csv\n",
    "reader = csv.reader(open('testset_w-unique_labeled.csv', 'r', encoding =\"utf-8\"),delimiter=';')\n",
    "labeled = {}\n",
    "for row in reader:\n",
    "    #need to adjust the number of empty fields\n",
    "    k,_,_,_,v = row\n",
    "    labeled[k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 1190/1190 [00:00<00:00, 7271.59it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 2548/2548 [00:00<00:00, 16719.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen via background domain: 2330\n",
      "Chosen via metric: 3873\n",
      "Chosen via tf > 1 limit: 14983\n"
     ]
    }
   ],
   "source": [
    "labels = domain_relevance.label_concepts(audi_domain, adac_domain, chefkoch_domain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zumal überbrückungsfahrzeug fast 4 is\n",
      "vertraut ... alltagsauto\n",
      "mal komplett unterschiedliche werte\n",
      "z-diode\n",
      "ersatzteillos\n",
      "evtl anfängersichere anleitung\n",
      "raum aachen-köln\n",
      "gelben/orangen blinkern\n",
      "tausche 1 dämpfer querlenker idioten\n",
      "vw tl\n",
      "abs ?\n",
      "kurvenäußeren rad\n",
      "audi v8 4,2l\n",
      "gewinnbringende antworten\n",
      "degenhard\n",
      "dauerhaft auf'n\n",
      "ansaugrohrvorw\n",
      "schwungs\n",
      "handelbezeichnungen\n"
     ]
    }
   ],
   "source": [
    "predicted = {}\n",
    "for candidate in testset:\n",
    "    try:\n",
    "        predicted[candidate] = labels[candidate]\n",
    "    except KeyError:\n",
    "        predicted[candidate] = 0\n",
    "        print(candidate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame.from_dict(labeled,orient='index', columns = [\"label\"])\n",
    "df[\"predicted\"] = predicted.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[517, 229],\n",
       "       [ 68, 186]], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(pd.to_numeric(df[\"label\"]), pd.to_numeric(df[\"predicted\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.69      0.78       746\n",
      "           1       0.45      0.73      0.56       254\n",
      "\n",
      "    accuracy                           0.70      1000\n",
      "   macro avg       0.67      0.71      0.67      1000\n",
      "weighted avg       0.77      0.70      0.72      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(pd.to_numeric(df[\"label\"]), pd.to_numeric(df[\"predicted\"])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

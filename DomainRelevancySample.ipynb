{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Domain Relevancy Sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overview of methods used to determine Domain Relevance. In practice three domains are used ADAC, Autoforum & Chefkochforum. Also terms are cleaned before calculating frequencies - this step is skipped since all terms are of high quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation of two sample datasets\n",
    "Each set consists of a list of documents which each contain a list of terms defining the document. Storing the domains as \"list of lists\" allows to calculate term-frequency as well as term-document-frequency or inverse-document-frequency more easily in later stages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = [\"hallo\", \"auto\", \"problem\", \"grüße\"]\n",
    "doc2 = [\"hallo\", \"auto\", \"sensor\", \"fehler\"]\n",
    "doc3 = [\"hallo\", \"reifen\", \"fehler\", \"dank\"]\n",
    "doc4 = [\"hi\", \"sensor\", \"kaputt\", \"grüße\"]\n",
    "\n",
    "target_domain = [doc1, doc2, doc3, doc4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = [\"hallo\", \"haus\", \"garten\", \"grüße\"]\n",
    "doc2 = [\"hallo\", \"sommer\", \"haus\", \"grüße\"]\n",
    "doc3 = [\"hi\", \"regen\", \"pflanzen\", \"dank\"]\n",
    "doc4 = [\"hi\", \"garten\", \"zaun\", \"grüße\"]\n",
    "\n",
    "contrastive_domain = [doc1, doc2, doc3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Relevancy Measures\n",
    "Presented are three approaches: \n",
    "1. combinations of term-frequency, term-document-frequency, inverse-term-document-frequency\n",
    "2. domain relevance / domain consensus measure from \"Ontolearn\" System (link!!!)\n",
    "3. log-likelihood measure from textbook "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a) normalized term-frequency\n",
    "tf = term-frequency / max_term-frequency\n",
    "\n",
    "**idea:** terms that appear most are imporant \n",
    "\n",
    "\n",
    "-basic idea: pg. 105ff of https://web.stanford.edu/~jurafsky/slp3/\n",
    "\n",
    "-normalized idea in https://onlinelibrary.wiley.com/doi/abs/10.1002/asi.21231"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tf(terms, norm = 0):\n",
    "    flat_terms = [item for sublist in terms for item in sublist]\n",
    "    tf = Counter(flat_terms)\n",
    "    max_freq = Counter(flat_terms).most_common(1)[0][1]\n",
    "    n = len(set(flat_terms))\n",
    "    for t in tf:\n",
    "        if norm:\n",
    "            tf[t] = (tf[t] / max_freq)\n",
    "        else:\n",
    "            tf[t] = (tf[t] / n)\n",
    "\n",
    "    return tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'hallo': 1.0,\n",
       "         'auto': 0.6666666666666666,\n",
       "         'problem': 0.3333333333333333,\n",
       "         'grüße': 0.6666666666666666,\n",
       "         'sensor': 0.6666666666666666,\n",
       "         'fehler': 0.6666666666666666,\n",
       "         'reifen': 0.3333333333333333,\n",
       "         'dank': 0.3333333333333333,\n",
       "         'hi': 0.3333333333333333,\n",
       "         'kaputt': 0.3333333333333333})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_tf(target_domain, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1b) normalized term-document-frequency\n",
    "tdf = term-document-frequency / max_term-document-frequency\n",
    "\n",
    "**idea:** terms that appear often in docuemts are important\n",
    "\n",
    "-basic idea: pg. 105ff of https://web.stanford.edu/~jurafsky/slp3/\n",
    "\n",
    "-normalized idea in https://onlinelibrary.wiley.com/doi/abs/10.1002/asi.21231"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tdf(terms):\n",
    "    flat_terms = [item for sublist in terms for item in set(sublist)]\n",
    "    tdf = Counter(flat_terms)\n",
    "    max_freq = Counter(flat_terms).most_common(1)[0][1]\n",
    "    for t in tdf:\n",
    "        tdf[t] = tdf[t] / max_freq\n",
    "\n",
    "    return tdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'hallo': 1.0,\n",
       "         'auto': 0.6666666666666666,\n",
       "         'grüße': 0.6666666666666666,\n",
       "         'problem': 0.3333333333333333,\n",
       "         'sensor': 0.6666666666666666,\n",
       "         'fehler': 0.6666666666666666,\n",
       "         'dank': 0.3333333333333333,\n",
       "         'reifen': 0.3333333333333333,\n",
       "         'hi': 0.3333333333333333,\n",
       "         'kaputt': 0.3333333333333333})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_tdf(target_domain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1c) inverse-term-document-frequency\n",
    "idf = log2( 1 / tdf[])\n",
    "\n",
    "**idea:** terms that appear too much are irrelevant\n",
    "\n",
    "(commonly used to filter out words like is, have, i, you)\n",
    "\n",
    "basic idea: pg. 105ff of https://web.stanford.edu/~jurafsky/slp3/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_idf(terms):\n",
    "    flat_terms = [item for sublist in terms for item in set(sublist)]\n",
    "    idf = Counter(flat_terms)\n",
    "    for t in idf:\n",
    "        idf[t] = np.log2(len(terms) / idf[t])\n",
    "\n",
    "    return idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'hallo': 0.5849625007211562,\n",
       "         'haus': 0.5849625007211562,\n",
       "         'grüße': 0.5849625007211562,\n",
       "         'garten': 1.584962500721156,\n",
       "         'sommer': 1.584962500721156,\n",
       "         'pflanzen': 1.584962500721156,\n",
       "         'hi': 1.584962500721156,\n",
       "         'dank': 1.584962500721156,\n",
       "         'regen': 1.584962500721156})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_idf(contrastive_domain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) domain relevance / domain consensus measure (Ontolearn)\n",
    "DR = target-frequency / contrastive-frequency \n",
    "\n",
    "DC = target-tdf * log2( 1 / target-tdf )\n",
    "\n",
    "DW = alpha * DR + (1-alpha) * DC\n",
    "\n",
    "**idea:** domain relevane (DR) determines whether a term is more important to the target or contrastive domain, domain consensus determines whether that term is generic (i.e. appears a lot in every domain) - final result is a combination of both measures \n",
    "\n",
    "from https://ieeexplore.ieee.org/document/1179190"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dr(target_domain, contrastive_domain, candidates):\n",
    "    # candidates should be part of the target domain\n",
    "    dr = {}\n",
    "    \n",
    "    target_tf = get_tf(target_domain)\n",
    "    contrastive_tf = get_tf(contrastive_domain)\n",
    "\n",
    "    for term in candidates:\n",
    "        try:\n",
    "            dr[term] = target_tf[term] / contrastive_tf[term]\n",
    "        except ZeroDivisionError:\n",
    "            dr[term] = 0\n",
    "\n",
    "    return dr\n",
    "\n",
    "\n",
    "def get_dc(target_domain, candidates):\n",
    "    dc = {}\n",
    "    target_tdf = get_tdf(target_domain)\n",
    "\n",
    "    for term in candidates:\n",
    "        dc[term] = target_tdf[term]*np.log2(1/target_tdf[term])\n",
    "\n",
    "    return dc\n",
    "\n",
    "\n",
    "def get_dw(target_domain, contrastive_domain, candidates, alpha):\n",
    "    dw = {}\n",
    "    dr = get_dr(target_domain, contrastive_domain, candidates)\n",
    "    dc = get_dc(target_domain, candidates)\n",
    "\n",
    "    for term in candidates:\n",
    "        dw[term] = alpha * dr[term] + (1 - alpha) * dc[term]\n",
    "\n",
    "    return dw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sensor': 0.1949875002403854,\n",
       " 'fehler': 0.1949875002403854,\n",
       " 'hi': 0.7141604167868594,\n",
       " 'hallo': 0.675,\n",
       " 'kaputt': 0.2641604167868593,\n",
       " 'grüße': 0.6449875002403854,\n",
       " 'auto': 0.1949875002403854,\n",
       " 'problem': 0.2641604167868593,\n",
       " 'dank': 0.7141604167868594,\n",
       " 'reifen': 0.2641604167868593}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidates = set([item for sublist in target_domain for item in sublist])\n",
    "get_dw(target_domain, contrastive_domain, candidates, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Log-likelihood-ratio\n",
    "<img src=\"img/llr.png\" width=50% />\n",
    "Where \"i\" is the taget domain and \"j\" is the contrastive domain\n",
    "\n",
    "pg. 406 of https://web.stanford.edu/~jurafsky/slp3/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_llr(target_domain, contrastive_domain, candidates):\n",
    "    # candidates should be part of the target domain\n",
    "    llr = {}\n",
    "    target_tf = get_tf(target_domain)\n",
    "    contrastive_tf = get_tf(contrastive_domain)\n",
    "    \n",
    "    for term in candidates: \n",
    "        target_tf[term] = 0.1 if not target_tf[term] else target_tf[term]\n",
    "        contrastive_tf[term] = 0.1 if not contrastive_tf[term] else contrastive_tf[term]\n",
    "        \n",
    "        llr[term] = np.log(target_tf[term]) - np.log(contrastive_tf[term])\n",
    " \n",
    "    return llr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sensor': 0.6931471805599452,\n",
       " 'fehler': 0.6931471805599452,\n",
       " 'hi': -0.10536051565782589,\n",
       " 'hallo': 0.30010459245033805,\n",
       " 'kaputt': 0.0,\n",
       " 'grüße': -0.10536051565782611,\n",
       " 'auto': 0.6931471805599452,\n",
       " 'problem': 0.0,\n",
       " 'dank': -0.10536051565782589,\n",
       " 'reifen': 0.0}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_llr(target_domain, contrastive_domain, candidates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3b) Log-odds-ratio\n",
    "\n",
    "<img src=\"img/lor.png\" width=50% />\n",
    "\n",
    "Where \"i\" is the taget domain and \"j\" is the contrastive domain\n",
    "\n",
    "pg. 407 of https://web.stanford.edu/~jurafsky/slp3/\n",
    "\n",
    "Note: Can also be used with background knowledge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lor(target_domain, contrastive_domain, candidates):\n",
    "    # candidates should be part of the target domain\n",
    "    lor = {}\n",
    "    target_tf = get_tf(target_domain)\n",
    "    contrastive_tf = get_tf(contrastive_domain)\n",
    "    \n",
    "    for term in candidates: \n",
    "        target_tf[term] = 0.0001 if not target_tf[term] else target_tf[term]\n",
    "        contrastive_tf[term] = 0.0001 if not contrastive_tf[term] else contrastive_tf[term]\n",
    "        \n",
    "        lor[term] = np.log2(target_tf[term]/(1-target_tf[term])) - np.log2(contrastive_tf[term]/(1-contrastive_tf[term]))\n",
    " \n",
    "    return lor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sensor': 11.287568102831404,\n",
       " 'fehler': 11.287568102831404,\n",
       " 'hi': -0.16992500144231215,\n",
       " 'hallo': 0.5849625007211563,\n",
       " 'kaputt': 10.117643101389092,\n",
       " 'grüße': -0.19264507794239583,\n",
       " 'auto': 11.287568102831404,\n",
       " 'problem': 10.117643101389092,\n",
       " 'dank': -0.16992500144231215,\n",
       " 'reifen': 10.117643101389092}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_lor(target_domain, contrastive_domain, candidates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3c) Log-odds-ratio with background knowledge\n",
    "\n",
    "<img src=\"img/lor_bg.png\" width=50% />\n",
    "\n",
    "from pg. 407 of https://web.stanford.edu/~jurafsky/slp3/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def get_lor_bg(target_domain, contrastive_domain, candidates, normalized = 0):\n",
    "    # candidates should be part of the target domain\n",
    "    lor_bg = {}\n",
    "    \n",
    "    # get term frequency for each domain - combining both gives background knowledge\n",
    "    target_flat_terms = [item for sublist in target_domain for item in sublist]\n",
    "    target_tf = Counter(target_flat_terms)\n",
    "    \n",
    "    contrastive_flat_terms = [item for sublist in contrastive_domain for item in sublist]\n",
    "    contrastive_tf = Counter(contrastive_flat_terms)\n",
    "    \n",
    "    combine_flat_terms = target_flat_terms + contrastive_flat_terms\n",
    "    combine_tf = Counter(combine_flat_terms)\n",
    "    \n",
    "    n_i = len(target_flat_terms)\n",
    "    n_j = len(contrastive_flat_terms)\n",
    "    a_0 = len(combine_flat_terms)\n",
    "    \n",
    "    for term in candidates: \n",
    "        target_tf[term] = 0.1 if not target_tf[term] else target_tf[term]\n",
    "        contrastive_tf[term] = 0.1 if not contrastive_tf[term] else contrastive_tf[term]\n",
    "        combine_tf[term] = 0.1 if not combine_tf[term] else contrastive_tf[term]\n",
    "        \n",
    "        lor_bg[term] = np.log2((target_tf[term]+combine_tf[term])/n_i + a_0 - (target_tf[term]+combine_tf[term])) - np.log2((contrastive_tf[term]+combine_tf[term])/ n_i + a_0 - (contrastive_tf[term]+combine_tf[term]))\n",
    "        if normalized:\n",
    "            sigma = 1/(target_tf[term] + combine_tf[term]) + 1/(contrastive_tf[term] + combine_tf[term])\n",
    "            lor_bg[term] = lor_bg[term] / math.sqrt(sigma)\n",
    "    return lor_bg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sensor': -0.040804996690351154,\n",
       " 'fehler': -0.040804996690351154,\n",
       " 'hi': 0.0,\n",
       " 'hallo': -0.08479322111290803,\n",
       " 'kaputt': -0.018283544476431025,\n",
       " 'grüße': 0.0,\n",
       " 'auto': -0.040804996690351154,\n",
       " 'problem': -0.018283544476431025,\n",
       " 'dank': 0.0,\n",
       " 'reifen': -0.018283544476431025}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_lor_bg(target_domain, contrastive_domain, candidates, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spacy",
   "language": "python",
   "name": "spacy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Domain Relevancy Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation of two sample datasets\n",
    "Each set consists of a list of documents which each contain a list of terms defining the document. Storing the domains as \"list of lists\" allows to calculate term-frequency as well as term-document-frequency or inverse-document-frequency more easily in later stages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = [\"hallo\", \"auto\", \"problem\", \"grüße\"]\n",
    "doc2 = [\"hallo\", \"auto\", \"sensor\", \"fehler\"]\n",
    "doc3 = [\"hallo\", \"reifen\", \"fehler\", \"dank\"]\n",
    "doc4 = [\"hi\", \"sensor\", \"kaputt\", \"grüße\"]\n",
    "\n",
    "target_domain = [doc1, doc2, doc3, doc4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = [\"hallo\", \"haus\", \"garten\", \"grüße\"]\n",
    "doc2 = [\"hallo\", \"sommer\", \"haus\", \"grüße\"]\n",
    "doc3 = [\"hi\", \"regen\", \"pflanzen\", \"dank\"]\n",
    "doc4 = [\"hi\", \"garten\", \"zaun\", \"grüße\"]\n",
    "\n",
    "contrastive_domain = [doc1, doc2, doc3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Relevancy Measures\n",
    "Presented are three approaches: \n",
    "1. combinations of term-frequency, term-document-frequency, inverse-term-document-frequency\n",
    "2. domain relevance / domain consensus measure from \"Ontolearn\" System (link!!!)\n",
    "3. log-likelihood measure from textbook "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a) normalized term-frequency\n",
    "tf = term-frequency / max_term-frequency\n",
    "\n",
    "**idea:** terms that appear most are imporant "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tf(terms):\n",
    "    flat_terms = [item for sublist in terms for item in sublist]\n",
    "    tf = Counter(flat_terms)\n",
    "    max_freq = Counter(flat_terms).most_common(1)[0][1]\n",
    "    for t in tf:\n",
    "        tf[t] = (tf[t] / max_freq)\n",
    "\n",
    "    return tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'hallo': 1.0,\n",
       "         'auto': 0.6666666666666666,\n",
       "         'problem': 0.3333333333333333,\n",
       "         'grüße': 0.6666666666666666,\n",
       "         'sensor': 0.6666666666666666,\n",
       "         'fehler': 0.6666666666666666,\n",
       "         'reifen': 0.3333333333333333,\n",
       "         'dank': 0.3333333333333333,\n",
       "         'hi': 0.3333333333333333,\n",
       "         'kaputt': 0.3333333333333333})"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_tf(target_domain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1b) normalized term-document-frequency\n",
    "tdf = term-document-frequency / max_term-document-frequency\n",
    "\n",
    "**idea:** terms that appear often in docuemts are important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tdf(terms):\n",
    "    flat_terms = [item for sublist in terms for item in set(sublist)]\n",
    "    tdf = Counter(flat_terms)\n",
    "    max_freq = Counter(flat_terms).most_common(1)[0][1]\n",
    "    for t in tdf:\n",
    "        tdf[t] = tdf[t] / max_freq\n",
    "\n",
    "    return tdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'hallo': 1.0,\n",
       "         'auto': 0.6666666666666666,\n",
       "         'problem': 0.3333333333333333,\n",
       "         'grüße': 0.6666666666666666,\n",
       "         'fehler': 0.6666666666666666,\n",
       "         'sensor': 0.6666666666666666,\n",
       "         'reifen': 0.3333333333333333,\n",
       "         'dank': 0.3333333333333333,\n",
       "         'kaputt': 0.3333333333333333,\n",
       "         'hi': 0.3333333333333333})"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_tdf(target_domain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1c) inverse-term-document-frequency\n",
    "idf = log2( 1 / tdf[])\n",
    "\n",
    "**idea:** terms that appear too much are irrelevant\n",
    "\n",
    "(commonly used to filter out words like is, have, i, you)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_idf(terms):\n",
    "    flat_terms = [item for sublist in terms for item in set(sublist)]\n",
    "    idf = Counter(flat_terms)\n",
    "    for t in idf:\n",
    "        idf[t] = np.log2(len(terms) / idf[t])\n",
    "\n",
    "    return idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'hallo': 0.5849625007211562,\n",
       "         'haus': 0.5849625007211562,\n",
       "         'grüße': 0.5849625007211562,\n",
       "         'garten': 1.584962500721156,\n",
       "         'sommer': 1.584962500721156,\n",
       "         'pflanzen': 1.584962500721156,\n",
       "         'dank': 1.584962500721156,\n",
       "         'hi': 1.584962500721156,\n",
       "         'regen': 1.584962500721156})"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_idf(contrastive_domain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) domain relevance / domain consensus measure (Ontolearn)\n",
    "DR = target-frequency / contrastive-frequency \n",
    "\n",
    "DC = target-tdf * log2( 1 / target-tdf )\n",
    "\n",
    "DW = alpha * DR + (1-alpha) * DC\n",
    "\n",
    "**idea:** domain relevane (DR) determines whether a term is more important to the target or contrastive domain, domain consensus determines whether that term is generic (i.e. appears a lot in every domain) - final result is a combination of both measures "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dr(target_domain, contrastive_domain, candidates):\n",
    "    # candidates should be part of the target domain\n",
    "    dr = {}\n",
    "    target_tf = get_tf(target_domain)\n",
    "    contrastive_tf = get_tf(contrastive_domain)\n",
    "\n",
    "    for term in candidates:\n",
    "        try:\n",
    "            dr[term] = target_tf[term] / contrastive_tf[term]\n",
    "        except ZeroDivisionError:\n",
    "            dr[term] = 0\n",
    "\n",
    "    return dr\n",
    "\n",
    "\n",
    "def get_dc(target_domain, candidates):\n",
    "    dc = {}\n",
    "    target_tdf = get_tdf(target_domain)\n",
    "\n",
    "    for term in candidates:\n",
    "        dc[term] = target_tdf[term]*np.log2(1/target_tdf[term])\n",
    "\n",
    "    return dc\n",
    "\n",
    "\n",
    "def get_dw(target_domain, contrastive_domain, candidates, alpha):\n",
    "    dw = {}\n",
    "    dr = get_dr(target_domain, contrastive_domain, candidates)\n",
    "    dc = get_dc(target_domain, candidates)\n",
    "\n",
    "    for term in candidates:\n",
    "        dw[term] = alpha * dr[term] + (1 - alpha) * dc[term]\n",
    "\n",
    "    return dw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hi': 0.5974937501201927,\n",
       " 'kaputt': 0.2641604167868593,\n",
       " 'hallo': 0.5,\n",
       " 'dank': 0.5974937501201927,\n",
       " 'fehler': 0.1949875002403854,\n",
       " 'grüße': 0.5283208335737187,\n",
       " 'sensor': 0.1949875002403854,\n",
       " 'reifen': 0.2641604167868593,\n",
       " 'problem': 0.2641604167868593,\n",
       " 'auto': 0.1949875002403854}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidates = set([item for sublist in terms for item in sublist])\n",
    "get_dw(target_domain, contrastive_domain, candidates, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Log-likelihood-ratio\n",
    "llr = log( target-tf ) - log( contrastive-tf )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_llr(target_domain, contrastive_domain, candidates):\n",
    "    # candidates should be part of the target domain\n",
    "    llr = {}\n",
    "    target_tf = get_tf(target_domain)\n",
    "    contrastive_tf = get_tf(contrastive_domain)\n",
    "    \n",
    "    for term in candidates: \n",
    "        target_tf[term] = 0.1 if not target_tf[term] else target_tf[term]\n",
    "        contrastive_tf[term] = 0.1 if not contrastive_tf[term] else contrastive_tf[term]\n",
    "        \n",
    "        llr[term] = np.log(target_tf[term]) - np.log(contrastive_tf[term])\n",
    " \n",
    "    return llr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hi': -0.4054651081081645,\n",
       " 'kaputt': 1.2039728043259357,\n",
       " 'hallo': 0.0,\n",
       " 'dank': -0.4054651081081645,\n",
       " 'fehler': 1.897119984885881,\n",
       " 'grüße': -0.40546510810816444,\n",
       " 'sensor': 1.897119984885881,\n",
       " 'reifen': 1.2039728043259357,\n",
       " 'problem': 1.2039728043259357,\n",
       " 'auto': 1.897119984885881}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_llr(target_domain, contrastive_domain, candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_concepts(candidates, target_domain, contrastive_domain):\n",
    "    concepts = set()\n",
    "    \n",
    "    for candidate in candidates:\n",
    "        try:\n",
    "            contrastive_domain[candidate]\n",
    "        except KeyError:\n",
    "            contrastive_domain[candidate] = 0\n",
    "            \n",
    "        if adac_terms[candidate] > chefkoch_terms[candidate]:\n",
    "            concepts.add(candidate)\n",
    "    return concepts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spacy",
   "language": "python",
   "name": "spacy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

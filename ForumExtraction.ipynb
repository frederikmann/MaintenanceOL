{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forum Extraction\n",
    "\n",
    "starting with https://www.motor-talk.de/forum/start-probleme-audi-a6-c4-2-6-abc-t6820263.html?page=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "from spacy.matcher import Matcher \n",
    "from spacy.pipeline import Sentencizer\n",
    "from parts import collect, preprocessing, oie, domain_relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"de_core_news_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### General SpaCy setup\n",
    "\n",
    "sentencizer = Sentencizer(punct_chars=[\".\", \"?\", \"!\", \",\", \";\"])\n",
    "nlp.add_pipe(sentencizer, name=\"sentence_segmenter\", before=\"parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collecting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link = \"https://www.motor-talk.de/forum/start-probleme-audi-a6-c4-2-6-abc-t6820263.html\"\n",
    "\n",
    "p = collect.get_text_car(link)\n",
    "print(len(p))\n",
    "\n",
    "forum_text = \" ; \".join(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize lowercase = TRUE, remove_stopwords = FALSE\n",
    "normalized = preprocessing.normalize(forum_text, 1, 0)\n",
    "\n",
    "# clean no_questions = TRUE\n",
    "cleaned = preprocessing.clean(normalized, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"sentences.txt\", 'w') as output:\n",
    "    output.write(cleaned.replace(\"; \", \"\\n\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OIE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roots, terms, sents = oie.get_oie(cleaned)\n",
    "\n",
    "terms2 = []\n",
    "for sent in terms:\n",
    "    terms2.append(\", \".join(sent))\n",
    "\n",
    "df = pd.DataFrame(roots, columns=[\"roots\"])\n",
    "df[\"terms\"] = pd.DataFrame(terms2)\n",
    "df[\"sents\"] = pd.DataFrame(sents)\n",
    "\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Domain Relevancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_relevancy = domain_relevance.main(link, terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_concepts(candidates, threshold):\n",
    "    concepts = set()\n",
    "\n",
    "    for candidate in candidates:\n",
    "        if domain_relevancy[candidate] > threshold:\n",
    "            concepts.add(candidate)\n",
    "\n",
    "    return concepts\n",
    "\n",
    "concepts = get_concepts(domain_relevancy, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sent in terms:\n",
    "    for term in sent:\n",
    "        if term not in concepts and not in nlp.Default.stop_words:\n",
    "            term = \"\"\n",
    "\n",
    "terms2 = []\n",
    "for sent in terms:\n",
    "    terms2.append(\", \".join(sent))\n",
    "\n",
    "df = pd.DataFrame(roots, columns=[\"roots\"])\n",
    "df[\"terms\"] = pd.DataFrame(terms2)\n",
    "df[\"sents\"] = pd.DataFrame(sents)\n",
    "\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv (\"20200528_term-extraction.csv\", index = False, header=True, sep = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = []\n",
    "for sent in terms:\n",
    "    p = 0\n",
    "    for term in sent:\n",
    "        if term:\n",
    "            p = 1\n",
    "    predicted.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"resources/20200528_gold-standard-forumpost.csv\", delimiter=\";\", names=[\"label\",\"sent\"])\n",
    "df[\"predicted\"] = pd.DataFrame(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(df[\"label\"], df[\"predicted\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx \n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "\n",
    "G = nx.Graph()\n",
    "nodeA = []\n",
    "nodeB = []\n",
    "relation = []\n",
    "\n",
    "for sent, root in zip(terms, roots):\n",
    "    prev_term = 0\n",
    "    for term in sent:\n",
    "        if prev_term:\n",
    "            G.add_edge(prev_term, term)\n",
    "            nodeA.append(prev_term)\n",
    "            nodeB.append(term)\n",
    "            relation.append(root)\n",
    "        else:\n",
    "            prev_term = term\n",
    "pos = nx.spring_layout(G, k=0.15, iterations=20)\n",
    "plt.figure(figsize=(12,12))\n",
    "nx.draw(G,pos,width=1,linewidths=1,node_size=500,alpha=0.9,labels={node:node for node in G.nodes()})\n",
    "labels = dict(zip(list(zip(nodeA, nodeB)),relation))\n",
    "nx.draw_networkx_edge_labels(G,pos,edge_labels=labels,font_color='red')\n",
    "\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spacy",
   "language": "python",
   "name": "spacy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

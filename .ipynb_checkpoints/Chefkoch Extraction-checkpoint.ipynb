{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chefkoch Term Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import requests as req\n",
    "from bs4 import BeautifulSoup\n",
    "from parts import collect, preprocessing, oie, domain_relevance\n",
    "\n",
    "nlp = spacy.load(\"de_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chefkoch_links(topic):\n",
    "    links = []\n",
    "    r = req.get(topic)\n",
    "    soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "    \n",
    "    for link in soup.find_all(\"a\", {\"class\":\"search-result-title\"}):\n",
    "        links.append(\"https://www.chefkoch.de\"+link[\"href\"])\n",
    "    \n",
    "    while soup.find(\"a\", {\"class\":\"pagination-item pagination-next\"}):\n",
    "        page = \"https://www.chefkoch.de\" + soup.find(\"a\", {\"class\":\"pagination-item pagination-next\"})[\"href\"]\n",
    "        r = req.get(page)\n",
    "        soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "        for link in soup.find_all(\"a\", {\"class\":\"search-result-title\"}):\n",
    "            links.append(\"https://www.chefkoch.de\"+link[\"href\"])\n",
    "        break\n",
    "           \n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic = \"https://www.chefkoch.de/forum/1,27/Haus-Garten.html\"\n",
    "\n",
    "links = get_chefkoch_links(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dirty fix -> link is broken \n",
    "\n",
    "links[82] = \"https://www.chefkoch.de/forum/2,22,768891/Darf-ein-Coronakranker-Post-verschicken.html\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def get_chefkoch_domain(links):\n",
    "    domain = []\n",
    "    \n",
    "    for link in tqdm(links):\n",
    "        chefkoch_text = \" ; \".join(collect.get_text_cook(link))\n",
    "        if len(chefkoch_text) < 100000 and chefkoch_text:\n",
    "            domain.append(chefkoch_text)\n",
    "    \n",
    "    return domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:54<00:00,  1.14s/it]\n"
     ]
    }
   ],
   "source": [
    "chefkoch_domain = get_chefkoch_domain(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chefkoch_domain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_terms(corpus):\n",
    "    terms = []\n",
    "    \n",
    "    doc = nlp(corpus.lower())\n",
    "    \n",
    "    for token in doc:\n",
    "        if token.pos_ in [\"NOUN\", \"PROPN\"] and not token.is_stop:\n",
    "            terms.append(token.lemma_)\n",
    "    \n",
    "    return terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [00:26<00:00,  3.49it/s]\n"
     ]
    }
   ],
   "source": [
    "terms = [get_terms(doc) for doc in tqdm(chefkoch_domain)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def get_tf(terms):\n",
    "    flat_terms = [item for sublist in terms for item in sublist]\n",
    "    tf = Counter(flat_terms)\n",
    "    max_freq = Counter(flat_terms).most_common(1)[0][1]\n",
    "    for t in tf:\n",
    "        tf[t] = (tf[t]/max_freq)\n",
    "    \n",
    "    return tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_idf(terms):\n",
    "    flat_terms = [item for sublist in terms for item in set(sublist)]\n",
    "    idf = Counter(flat_terms)\n",
    "    for t in idf:\n",
    "        idf[t] = np.log2(len(terms)/idf[t])\n",
    "    \n",
    "    return idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_tdf(terms):\n",
    "    flat_terms = [item for sublist in terms for item in set(sublist)]\n",
    "    tdf = Counter(flat_terms)\n",
    "    for t in tdf:\n",
    "        tdf[t] = tdf[t]/len(terms)\n",
    "    \n",
    "    return tdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = get_tf(terms)\n",
    "idf = get_idf(terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = {}\n",
    "\n",
    "for term in set([item for sublist in terms for item in sublist]):\n",
    "    tf_idf[term] = tf[term]*idf[term]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.Series(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hallo            1.000000\n",
       "grüße            0.211635\n",
       "wasser           0.205617\n",
       "maschine         0.178536\n",
       "katir            0.177533\n",
       "lg               0.169509\n",
       "problem          0.152457\n",
       "putz             0.148445\n",
       "waschmaschine    0.146439\n",
       "garen            0.142427\n",
       "vögel            0.137412\n",
       "farbe            0.134403\n",
       "pflanzen         0.123370\n",
       "pflanze          0.119358\n",
       "fragen           0.118355\n",
       "dtype: float64"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(ascending = False).head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index().to_csv(\"chefkoch_terms.csv\", index = False, header=True, sep = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_term_cleaning(terms):\n",
    "    # clean zitate, datum, zeichen/ zahlen only terms, zeit, links\n",
    "    clean_terms = []\n",
    "    time, date, link, zitat, ireg, abbr = 0, 0, 0, 0, 0, 0\n",
    "    abbreviations = preprocessing.get_abbr()\n",
    "\n",
    "    for doc in terms:\n",
    "        clean_doc = []\n",
    "        for term in doc:\n",
    "            if len(term) < 2:\n",
    "                pass\n",
    "            elif re.search(r\"\\d\\d:\\d\\d:\\d\\d\", term):\n",
    "                time += 1\n",
    "            elif re.search(r\"\\d\\d.\\d\\d.\\d\\d\\d\\d\", term):\n",
    "                date += 1\n",
    "            elif re.search(\"https://\", term):\n",
    "                link += 1\n",
    "            elif re.search(\"@\", term):\n",
    "                zitat += 1\n",
    "            elif term in abbreviations:\n",
    "                abbr += 1\n",
    "            elif re.search(r\"\\w\", term):\n",
    "                clean_doc.append(term)\n",
    "            elif re.search(r\"^\\W\", term):\n",
    "                ireg += 1\n",
    "            else:\n",
    "                print(term)\n",
    "        clean_terms.append(clean_doc)\n",
    "\n",
    "    print(\"deleted time references:\", time)\n",
    "    print(\"deleted date references:\", date)\n",
    "    print(\"deleted links:\", link)\n",
    "    print(\"deleted quotes:\", zitat)\n",
    "    print(\"deleted ireg expressions:\", ireg)\n",
    "    print(\"deleted abbreviations:\", abbr)\n",
    "\n",
    "    return clean_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleted time references: 0\n",
      "deleted date references: 179\n",
      "deleted links: 31\n",
      "deleted quotes: 67\n",
      "deleted ireg expressions: 60\n",
      "deleted abbreviations: 110\n"
     ]
    }
   ],
   "source": [
    "clean_terms = post_term_cleaning(terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = get_tf(clean_terms)\n",
    "idf = get_idf(clean_terms)\n",
    "tdf = get_tdf(clean_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = {}\n",
    "tf_tdf = {}\n",
    "\n",
    "for term in set([item for sublist in clean_terms for item in sublist]):\n",
    "    tf_idf[term] = tf[term]*idf[term]\n",
    "    tf_tdf[term] = tf[term]*tdf[term]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.Series(tf_tdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index().to_csv(\"chefkoch_terms.csv\", index = False, header=True, sep = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spacy",
   "language": "python",
   "name": "spacy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
